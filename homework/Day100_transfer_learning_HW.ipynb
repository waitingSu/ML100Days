{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業\n",
    "礙於不是所有同學都有 GPU ，這邊的範例使用的是簡化版本的 ResNet，確保所有同學都能夠順利訓練!\n",
    "\n",
    "\n",
    "最後一天的作業請閱讀這篇非常詳盡的[文章](https://blog.gtwang.org/programming/keras-resnet-50-pre-trained-model-build-dogs-cats-image-classification-system/)，基本上已經涵蓋了所有訓練　CNN 常用的技巧，請使用所有學過的訓練技巧，盡可能地提高 Cifar-10 的 test data 準確率，截圖你最佳的結果並上傳來完成最後一次的作業吧!\n",
    "\n",
    "另外這些技巧在 Kaggle 上也會被許多人使用，更有人會開發一些新的技巧，例如使把預訓練在 ImageNet 上的模型當成 feature extractor 後，再拿擷取出的特徵重新訓練新的模型，這些技巧再進階的課程我們會在提到，有興趣的同學也可以[參考](https://www.kaggle.com/insaff/img-feature-extraction-with-pretrained-resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# Disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau,EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from resnet_builder import resnet # 這是從 resnet_builder.py 中直接 import 撰寫好的 resnet 函數\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 # batch 的大小，如果出現 OOM error，請降低這個值\n",
    "num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n",
    "epochs = 30 # 訓練整個資料集共 30個循環"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 32, 32, 16)   448         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 32, 32, 16)   64          conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 32, 32, 16)   0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 32, 32, 16)   272         activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 32, 32, 16)   64          conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 32, 32, 16)   0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 32, 32, 16)   2320        activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 32, 32, 16)   64          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 32, 32, 16)   0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 32, 32, 64)   1088        activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 32, 32, 64)   1088        activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 32, 32, 64)   0           conv2d_97[0][0]                  \n",
      "                                                                 conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 32, 32, 64)   256         add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 32, 32, 64)   0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 32, 32, 16)   1040        activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 32, 32, 16)   64          conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 32, 32, 16)   0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 32, 32, 16)   2320        activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 32, 32, 16)   64          conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 32, 32, 16)   0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 32, 32, 64)   1088        activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 32, 32, 64)   0           add_27[0][0]                     \n",
      "                                                                 conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 32, 32, 64)   256         add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 32, 32, 64)   0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 32, 32, 16)   1040        activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 32, 32, 16)   64          conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 32, 32, 16)   0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 32, 32, 16)   2320        activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 32, 32, 16)   64          conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 32, 32, 16)   0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 32, 32, 64)   1088        activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 32, 32, 64)   0           add_28[0][0]                     \n",
      "                                                                 conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 32, 32, 64)   256         add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 32, 32, 64)   0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 16, 16, 64)   4160        activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 16, 16, 64)   256         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 16, 16, 64)   0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 16, 16, 64)   36928       activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 16, 16, 64)   256         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 16, 16, 64)   0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 16, 16, 128)  8320        add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 16, 16, 128)  8320        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 16, 16, 128)  0           conv2d_107[0][0]                 \n",
      "                                                                 conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 16, 16, 128)  512         add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 16, 16, 128)  0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 16, 16, 64)   8256        activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 16, 16, 64)   256         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 16, 16, 64)   0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 16, 16, 64)   36928       activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 16, 16, 64)   256         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 16, 16, 64)   0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 16, 16, 128)  8320        activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 16, 16, 128)  0           add_30[0][0]                     \n",
      "                                                                 conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 16, 16, 128)  512         add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 16, 16, 128)  0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 16, 16, 64)   8256        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 16, 16, 64)   256         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 16, 16, 64)   0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 16, 16, 64)   36928       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 16, 16, 64)   256         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 16, 16, 64)   0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 16, 16, 128)  8320        activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 16, 16, 128)  0           add_31[0][0]                     \n",
      "                                                                 conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 16, 16, 128)  512         add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 16, 16, 128)  0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 8, 8, 128)    16512       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 8, 8, 128)    512         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 8, 8, 128)    0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 8, 8, 128)    147584      activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 8, 8, 128)    512         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 8, 8, 128)    0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 8, 8, 256)    33024       add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 8, 8, 256)    33024       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 8, 8, 256)    0           conv2d_117[0][0]                 \n",
      "                                                                 conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 8, 8, 256)    1024        add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 8, 8, 256)    0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 8, 8, 128)    32896       activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 8, 8, 128)    512         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 8, 8, 128)    0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 8, 8, 128)    147584      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 8, 8, 128)    512         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 8, 8, 128)    0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 8, 8, 256)    33024       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 8, 8, 256)    0           add_33[0][0]                     \n",
      "                                                                 conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 8, 8, 256)    1024        add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 8, 8, 256)    0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 8, 8, 128)    32896       activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 8, 8, 128)    512         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 8, 8, 128)    0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 8, 8, 128)    147584      activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 8, 8, 128)    512         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 8, 8, 128)    0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 8, 8, 256)    33024       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 8, 8, 256)    0           add_34[0][0]                     \n",
      "                                                                 conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 8, 8, 256)    1024        add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 8, 8, 256)    0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 1, 1, 256)    0           activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 256)          0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           2570        flatten_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 849,002\n",
      "Trainable params: 843,786\n",
      "Non-trainable params: 5,216\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 建立 ResNet 模型\n",
    "model = resnet(input_shape=(32,32,3)) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 1.8679 - accuracy: 0.4957WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 818s 1s/step - loss: 1.8679 - accuracy: 0.4957 - val_loss: 2.3423 - val_accuracy: 0.4320\n",
      "Epoch 2/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 1.3966 - accuracy: 0.6262WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 902s 1s/step - loss: 1.3966 - accuracy: 0.6262 - val_loss: 1.5311 - val_accuracy: 0.5810\n",
      "Epoch 3/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 1.2107 - accuracy: 0.6824WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 959s 1s/step - loss: 1.2107 - accuracy: 0.6824 - val_loss: 1.7460 - val_accuracy: 0.5765\n",
      "Epoch 4/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 1.0877 - accuracy: 0.7202WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 954s 1s/step - loss: 1.0877 - accuracy: 0.7202 - val_loss: 1.5490 - val_accuracy: 0.6028\n",
      "Epoch 5/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.9944 - accuracy: 0.7493WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 945s 1s/step - loss: 0.9944 - accuracy: 0.7493 - val_loss: 1.4603 - val_accuracy: 0.6388\n",
      "Epoch 6/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.9419 - accuracy: 0.7674WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 961s 1s/step - loss: 0.9419 - accuracy: 0.7674 - val_loss: 1.0800 - val_accuracy: 0.7150\n",
      "Epoch 7/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.8996 - accuracy: 0.7797WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 972s 1s/step - loss: 0.8996 - accuracy: 0.7797 - val_loss: 0.9214 - val_accuracy: 0.7727\n",
      "Epoch 8/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.8573 - accuracy: 0.7912WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 931s 1s/step - loss: 0.8573 - accuracy: 0.7912 - val_loss: 1.1785 - val_accuracy: 0.7072\n",
      "Epoch 9/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.8268 - accuracy: 0.8023WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 927s 1s/step - loss: 0.8268 - accuracy: 0.8023 - val_loss: 1.2004 - val_accuracy: 0.7037\n",
      "Epoch 10/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.8024 - accuracy: 0.8074WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 982s 1s/step - loss: 0.8024 - accuracy: 0.8074 - val_loss: 0.9577 - val_accuracy: 0.7699\n",
      "Epoch 11/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.7766 - accuracy: 0.8142WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 973s 1s/step - loss: 0.7766 - accuracy: 0.8142 - val_loss: 1.1749 - val_accuracy: 0.7114\n",
      "Epoch 12/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.7573 - accuracy: 0.8213WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 974s 1s/step - loss: 0.7573 - accuracy: 0.8213 - val_loss: 1.0177 - val_accuracy: 0.7588\n",
      "Epoch 13/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.7362 - accuracy: 0.8292WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 927s 1s/step - loss: 0.7362 - accuracy: 0.8292 - val_loss: 0.9110 - val_accuracy: 0.7812\n",
      "Epoch 14/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.7257 - accuracy: 0.8305WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 939s 1s/step - loss: 0.7257 - accuracy: 0.8305 - val_loss: 1.1151 - val_accuracy: 0.7213\n",
      "Epoch 15/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.7053 - accuracy: 0.8370WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 943s 1s/step - loss: 0.7053 - accuracy: 0.8370 - val_loss: 1.0548 - val_accuracy: 0.7526\n",
      "Epoch 16/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.6948 - accuracy: 0.8410WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 938s 1s/step - loss: 0.6948 - accuracy: 0.8410 - val_loss: 0.8413 - val_accuracy: 0.8026\n",
      "Epoch 17/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.6830 - accuracy: 0.8439WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 961s 1s/step - loss: 0.6830 - accuracy: 0.8439 - val_loss: 0.9846 - val_accuracy: 0.7571\n",
      "Epoch 18/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.6694 - accuracy: 0.8487WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 934s 1s/step - loss: 0.6694 - accuracy: 0.8487 - val_loss: 0.7671 - val_accuracy: 0.8207\n",
      "Epoch 19/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.6614 - accuracy: 0.8495WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 946s 1s/step - loss: 0.6614 - accuracy: 0.8495 - val_loss: 0.9317 - val_accuracy: 0.7801\n",
      "Epoch 20/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.6463 - accuracy: 0.8560WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 947s 1s/step - loss: 0.6463 - accuracy: 0.8560 - val_loss: 0.9421 - val_accuracy: 0.7688\n",
      "Epoch 21/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.6418 - accuracy: 0.8555WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 953s 1s/step - loss: 0.6418 - accuracy: 0.8555 - val_loss: 0.9771 - val_accuracy: 0.7609\n",
      "Epoch 22/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.6302 - accuracy: 0.8598WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 944s 1s/step - loss: 0.6302 - accuracy: 0.8598 - val_loss: 0.8215 - val_accuracy: 0.7993\n",
      "Epoch 23/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.6163 - accuracy: 0.8638WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 943s 1s/step - loss: 0.6163 - accuracy: 0.8638 - val_loss: 0.8459 - val_accuracy: 0.8085\n",
      "Epoch 24/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.6167 - accuracy: 0.8630WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 939s 1s/step - loss: 0.6167 - accuracy: 0.8630 - val_loss: 0.7715 - val_accuracy: 0.8210\n",
      "Epoch 25/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.6071 - accuracy: 0.8665WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 949s 1s/step - loss: 0.6071 - accuracy: 0.8665 - val_loss: 0.7338 - val_accuracy: 0.8284\n",
      "Epoch 26/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.6001 - accuracy: 0.8683WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 936s 1s/step - loss: 0.6001 - accuracy: 0.8683 - val_loss: 1.2216 - val_accuracy: 0.7073\n",
      "Epoch 27/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5916 - accuracy: 0.8727WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 945s 1s/step - loss: 0.5916 - accuracy: 0.8727 - val_loss: 0.9365 - val_accuracy: 0.7742\n",
      "Epoch 28/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5875 - accuracy: 0.8736WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 918s 1s/step - loss: 0.5875 - accuracy: 0.8736 - val_loss: 0.8750 - val_accuracy: 0.8016\n",
      "Epoch 29/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5834 - accuracy: 0.8739WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 924s 1s/step - loss: 0.5834 - accuracy: 0.8739 - val_loss: 1.5210 - val_accuracy: 0.6737\n",
      "Epoch 30/30\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5785 - accuracy: 0.8745WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "781/781 [==============================] - 967s 1s/step - loss: 0.5785 - accuracy: 0.8745 - val_loss: 1.0180 - val_accuracy: 0.7606\n",
      "Test loss: 1.017978310585022\n",
      "Test accuracy: 0.7605999708175659\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "augment_generator = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.0009, \n",
    "                              min_lr=1e-12, \n",
    "                              monitor='val_loss', \n",
    "                              patience=10, \n",
    "                              verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor=\"val_acc\", \n",
    "                          patience=10, \n",
    "                          verbose=1\n",
    "                          )\n",
    "\n",
    "history = model.fit_generator(augment_generator.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=int(len(x_train)/batch_size), # 一個 epochs 要執行幾次 update，通常是資料量除以 batch size\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks=[reduce_lr,earlystop],          \n",
    "                    validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
