# ML100Days
第五屆機器學習百日馬拉松

### 1. 機器學習概論
#### 從概念上理解機器學習的目的與限制，並導覽機器學習流程
+ [Day1: 資料分析與評估資料](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_001_HW.ipynb)
+ [Day2: 機器學習概論](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_002_HW.ipynb)
+ [Day3: 機器學習-流程與步驟](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_003_HW.ipynb)
+ [Day4: EDA-讀取資料與分析流程](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_004_first_EDA.ipynb)

### 2. 資料清理數據前處理
#### 以滾動方式進行資料清理與探索性分析
+ [Day5: 如何新建一個DataFrame? 如何讀取其他資料?(非CSV資料)](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_005-1and2_HW.ipynb)
+ [Day6: EDA-欄位的資料類型介紹與處理](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_006_HW.ipynb)
+ [Day7: 特徵類型](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_007_HW.ipynb)
+ [Day8: EDA資料分佈](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_008_HW.ipynb)
+ [Day9: EDA: Outlier及處理](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_009_HW.ipynb)
+ [Day10: 數值型特徵-去除離群值](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_010_HW.ipynb)
+ [Day11: 常用的數值取代: 中位數與分位數連續數值標準化](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_011_HW.ipynb)
+ [Day12: 數值型特徵-補缺失值與標準化](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_012_HW.ipynb)
+ [Day13: DataFrame OperationData Frame Merge/常用的DataFrame操作](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_013_HW.ipynb)
+ [Day14: 程式實作EDA-Correlation/相關係數簡介](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_014_HW.ipynb)
+ [Day15: EDA from Correlation](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_015_HW.ipynb)
+ [Day16: EDA-不同數值範圍間的特徵如何檢視/繪圖與樣式Kernel Density Estimation(KDE)](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_016_HW.ipynb)
+ [Day17: EDA-把連續型變數離散化](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_017_HW.ipynb)
+ [Day18: 程式實作 把連續型變數離散化](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_018_HW.ipynb)
+ [Day19: Subplots](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_019_HW.ipynb)
+ [Day20: Heatmap & Grid-plot](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_020_HW.ipynb)
+ [Day21: 模型初體驗 Logistic Regression](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_021_HW.ipynb)

### 3. 資料科學特徵工程技術
#### 使用統計或領域知識，以各種組合調整方式，生成新特徵以提升模型預測力。
+ [Day22: 特徵工程簡介](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_022_HW.ipynb)
+ [Day23: 數值型特徵-去除偏態](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_023_HW.ipynb)
+ [Day24: 類別型特徵-基礎處理](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_024_HW.ipynb)
+ [Day25: 類別型特徵-均值編碼](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_025_HW.ipynb)
+ [Day26: 類別型特徵-其他進階處理](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_026_HW.ipynb)
+ [Day27: 時間型特徵](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_027_HW.ipynb)
+ [Day28: 特徵組合-數值與數值組合](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_028_HW.ipynb)
+ [Day29: 特徵組合-類別與數值組合](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_029_HW.ipynb)
+ [Day30: 特徵選擇](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_030_HW.ipynb)
+ [Day31: 特徵評估](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_031_HW.ipynb)
+ [Day32: 分類型特徵優化-葉編碼](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_032_HW.ipynb)

### 4. 機器學習基礎模型建立
#### 學習透過Scikit-learn等套件，建立機器學習模型並進行訓練！
+ [Day33: 機器如何學習?](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_033_HW.ipynb)
+ [Day34: 訓練/測試集切分的概念](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_034_HW.ipynb)
+ [Day35: rgression v.s classification](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_035_HW.ipynb)
+ [Day36: 評估指標選定/evaluation metrics](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_036_HW.ipynb)
+ [Day37: regression model 介紹-線性迴歸/羅吉斯回歸](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_037_HW.ipynb)
+ [Day38: regression model 程式碼撰寫(線性迴歸/羅吉斯回歸)](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_038_HW.ipynb)
+ [Day39: regression model 介紹-LASSO回歸/Ridge回歸](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_039_HW.ipynb)
+ [Day40: regression model 程式碼撰寫(LASSO回歸/Ridge回歸)](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_040_HW.ipynb)
+ [Day41: tree based model-決策樹(Decision Tree)模型介紹](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_041_HW.ipynb)
+ [Day42: tree Based Model-決策樹程式碼撰寫](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_042_HW.ipynb)
+ [Day43: tree Based Model-隨機森林(Random Forest)介紹](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_043_HW.ipynb)
+ [Day44: tree Based Model-隨機森林程式碼撰寫](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_044_HW.ipynb)
+ Day45: tree Based Model-梯度提升機(Gradient Boosting Machine)介紹 (無連結)
+ [Day46: tree Based Model-梯度提升機程式碼撰寫](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_046_HW.ipynb)

### 5. 機器學習調整參數
#### 了解模型內的參數意義，學習如何根據模型訓練情形來調整參數
+ [Day 47: 超參數調整與優化](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_047_HW.ipynb)
+ [Day 48: Kaggle 競賽平台介紹](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_048_HW.ipynb)
+ [Day49：集成方法 : 混合泛化(Blending)](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_049_Blending_HW.ipynb)
+ [Day50：集成方法 : 堆疊泛化(Stacking)](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_050_Stacking_HW.ipynb)
### Kaggle 第一次期中考
#### 機器學習成果驗收 考ML與調參相關
+ [Day51-53：Kaggle期中考 考ML與調參相關](https://github.com/waitingSu/ML100Days/blob/master/homework/D51_D53_Midterm.ipynb)
+ [Day51-53：Kaggle期中考 期限前最終分數](https://github.com/waitingSu/ML100Days/blob/master/homework/2020_ML100Marathon_Midtern.PNG)
### 6. 非監督式機器學習
#### 利用分群與降維方法探索資料模式
+ [Day54：clustering 1 非監督式機器學習簡介](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_054_HW.ipynb)
+ [Day55：clustering 2 聚類算法](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_055_HW.ipynb)
+ [Day56：K-mean 觀察 : 使用輪廓分析](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_056_kmean_HW.ipynb)
+ [Day57：clustering 3 階層分群算法](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_057_HW.ipynb)
+ [Day58：階層分群法 觀察 : 使用 2D 樣版資料集](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_058_hierarchical_clustering_HW.ipynb)
+ [Day59：dimension reduction 1 降維方法-主成份分析](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_059_HW.ipynb)
+ [Day60：PCA 觀察 : 使用手寫辨識資料集](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_060_PCA_HW.ipynb)
+ [Day62：t-sne 觀察 : 分群與流形還原](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_062_tsne_HW.ipynb)
### 7. 深度學習理論與實作
#### 神經網路的運用
+ [Day63：深度學習簡介](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_063_HW.ipynb)
+ [Day64：深度學習體驗 : 模型調整與學習曲線](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_064_HW.ipynb)
+ [Day65：深度學習體驗 : 啟動函數與正規化](https://github.com/waitingSu/ML100Days/blob/master/homework/Day_065_HW.ipynb)
### 8. 初探深度學習使用Keras
#### 學習機器學習(ML)與深度學習( DL) 的好幫手
+ [Day66：Keras 安裝與介紹](https://github.com/waitingSu/ML100Days/blob/master/homework/Day66-Keras_Introduction_HW.ipynb)
+ [Day67：Keras Dataset](https://github.com/waitingSu/ML100Days/blob/master/homework/Day67-Keras_Dataset_HW.ipynb)
+ [Day68：Keras Sequential API](https://github.com/waitingSu/ML100Days/blob/master/homework/Day68-Keras_Sequential_Model_HW.ipynb)
+ [Day69：Keras Module API](https://github.com/waitingSu/ML100Days/blob/master/homework/Day69-keras_Module_API_HW.ipynb)
+ [Day70：深度神經網路的基礎知識](https://github.com/waitingSu/ML100Days/blob/master/homework/Day70-Keras_Mnist_MLP_HW.ipynb)
+ [Day71：損失函數](https://github.com/waitingSu/ML100Days/commit/7b478cf42792d77a948244fd5c1c60a538fff5fd)
+ [Day72：啟動函數](https://github.com/waitingSu/ML100Days/commit/f3c2cddeba458651b1e33b0e87e2e0f976e39786)
+ [Day73：梯度下降Gradient Descent](https://github.com/waitingSu/ML100Days/commit/d9a1d3515f5bf050adfd8acc8a86d5facb14dabd)
+ [Day74：Gradient Descent 數學原理](https://github.com/waitingSu/ML100Days/blob/master/homework/Day74-Gradient_Descent_HW.ipynb)
+ [Day75：BackPropagation](https://github.com/waitingSu/ML100Days/blob/master/homework/Day75-Back_Propagation_HW.ipynb)
+ [Day76：優化器optimizers](https://github.com/waitingSu/ML100Days/blob/master/homework/D76-optimizer_HW.ipynb)
+ [Day77：訓練神經網路的細節與技巧 - Validation and overfit](https://github.com/waitingSu/ML100Days/blob/master/homework/Day077_HW.ipynb)
